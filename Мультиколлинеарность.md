#DataScience
Явление высокой ($>0.7$) корреляции между частью признаков объектов из выборки. Негативно сказывается на качестве тех моделей машинного обучения, которые не отбирают признаки самостоятельно (как при *$L_1$* регуляризации). 

Например, при использовании простой [[Линейная регрессия |линейной]] или [[Логистическая регрессия |логистической регрессии]], получающиеся в ходе обучение коэффициенты перестают иметь интерпретируемость и отражать реальную зависимость между целевым и прочими признаками.

Даже для тех моделей, которые отбирают признаки самостоятельно, рекомендуется избавляться от мультиколлинеарности: считается, что пары сильно коррелирующих признаков не привносят в данные новой полезной информации, зато приводят к расширению пространства признаков, и как следствие, всем негативным эффектам [[curse of dimensionality | проклятья размерности]].